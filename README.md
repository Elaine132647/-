# about the setting and how to execute the python file 
📌This explanation is for handover purposes only. \
📌Most of the explanations are included in the .ipynb file. Below are some potential solutions to issues you may encounter during execution. \
📌The following steps are optional; feel free to choose the method that suits you best. \
❓If you still have problems after reviewing, please reach out to me via email at eliana22680@gmail.com, but I can't guarantee a quick response. 


__0. 檔案說明__ \
📌此些檔案的執行方法均相同，僅取得之資料及其中的抓取元素不同，我會於最後一段簡單說明若要改動檔案以抓取其他網頁資訊可如何操作，僅供參考，具體更動方式仍須視網頁結構調整。
* 1111.ipynb: 用於抓取1111網站上公司之資訊，因電話及傳真號碼受到1111網站編碼限制，於此程序中僅可取得電話內容，且此兩項內容無法以UIPath方式取得，也無法以複製、貼上之方式取得。
* 104(record the similar company name).ipynb: 於使用時不會篩除與輸入之公司名稱不相符之公司資料，而是記錄所有於104排序時認定相關程度最高之公司名稱及相關資訊。(可能出現同一公司重複紀錄的狀況)
* 104.ipynb: 其中預設取得內容為將公司名稱以url encode帶入後最相關之內容，並加入公司名稱再次確認之限制，以確保取得正確公司資訊，其餘操作細節於其中註解說明，由於104網頁上各公司設定各項目時，使用的元素及設定或有不同，並非所有公司資料均可透過此方法取得。
* find_diff.ipynb: 用於比較取得之公司列與原有的公司列的差異，可找出尚未有紀錄的公司名稱。
* ver2_test.zip: 
  其中為UIPath的使用檔案，於此為避免設定過於複雜而出現錯誤，直接假設搜尋所得知公司均位於相關列表中的前兩項，另外，由於其設定最終選取物件是依據物件於當前頁面中的位置，而非完全依據其所使用的前端設計元素，因此，部分公司仍無法被取得，可考慮於執行後調整其中get attribute行為選取之項目的選擇位置，此調整方法亦適用於執行過程中出錯停止之情況。(然而，此調整方法可能造成後續執行問題，建議暫時跳過出現問題之公司，待其餘公司資料取得完畢後再進行調整)
* 下方兩個檔案由於先前回傳時無明確說明其執行後取得資訊支流成，因此，於此簡述說明:
  * 營業項目代碼.ipynb :
    * 步驟簡略說明:
      1. 僅取出原始檔案中"營業項目代碼"之內容作為關鍵字(即url中的keyword)帶入，即可取得所要的頁面。
      2. 需切分的文字部分，可透過正則表達式，完成字串的切分。
  * 台灣工業用地.ipynb : 為網站 **台灣工業用地https://idbpark.bip.gov.tw/ManufQuery/** 的爬蟲檔案， 詳細說明於檔案中，
    * 其中步驟大略為:
      1. 抓取資料總頁數，以調整url中帶入的參數，讓程序可以遍歷所有的資料頁面。
      2. 自每一頁內容中找出連結至各資訊業的網址或部分網址，與固定部分結合後以取得資訊頁面內容。
      3. 依據所需的資料位的層級和存放的html tag，取得文字內容並記錄。
  

__1. 使用環境__ \
 **‼️於工作結束後將會回復工位上電腦之設定，因此以下有關本機使用之內容，於9/30後若要使用均需自行重建。**
* Anaconda 下載連結 : https://www.anaconda.com/download
* 確認python成功安裝: 於anaconda prompt中輸入python --version (or python -V)，若結果顯示 Python 3.X.X，則為安裝成功。
* 安裝之套件: (於anaconda prompt中安裝)
  *  pip
  *  ipykernel
  *  檔案中import部分需要的封包
* 本機環境建構(optional，不使用此方法，確認本機存有python環境依然可以執行)
  於測試時，選用 anaconda 搭建env使用，以達到各執行序不會因調用同一驅動檔案而出錯之目的，\
  env建置指令如下: 
  * conda create --name my_env python=3.11 (python版本可自行變更)
  * 於jupyter notebook中使用創建之env: python -m ipykernel install --user --name my_env --display-name "Python (myenv)" (其中的name需與env名字相同，後方的display name可自由命名，與jupyter notebook中以display name呈現)
  * ⭐此指令需於anaconda prompt中輸入，此安裝無法確定是否將環境與cmd(本機環境)連接，因此，於本機環境中可能仍無法執行
    * 判斷是否與本機連動之方法:
      * 於cmd中輸入python --version，若無出現安裝之python版本，則無連接，可另外上網搜尋連接方法或以本說明中方法使用。  
* 於本機測試時所使用之版本為python 3.11 (可自行選擇慣於使用之版本，然而，於測試過程中並無對確認版本是否會對檔案執行造成影響進行確認，可自行評估選用)
* 測試時，使用自Anaconda navigator開啟之VScode，而非使用本機之VScode(於圖標及使用者頁面呈現均相同，僅環境不同，若同時開啟需注意)
  * 若完成本機環境安裝，則可使用本機之VScode 


__2. 所有的.ipynb檔均可於Google Colab上執行，使用方法:__
  * 上傳檔案，若出現env環境無法識別等相關警示，可直接忽略。
  * 於檔案中留有自本地端上傳檔案至colab之方法，僅需將該段程式碼註解取消即可。(詳細內容請見檔案中說明) (若有些檔案中沒有，可自其他檔案中直接複製使用)
  * 上傳後請注意上傳檔案之名稱與最後之main function中的檔案名稱是否相符，若不相符，請自行修改，否則將無法執行。
  * 以此方法所得之結果不會直接存到本地端或雲端硬碟中(除非與硬碟進行連接，連接方法可自行搜尋或詢問chatGPT)，需在程序執行完成後自行下載。
  * 請勿於執行過程中關閉網頁或開啟儲存結果之檔案，否則將造成執行失敗。

    
__3. 執行方法:__
  * 本地端執行:
    * 確認讀入之檔案。(請確認main function中的檔案名稱，而非於最一開始用於測試是否輸入正確之測試檔案名稱)
    * 詳細操作方式及程式碼註解使用請見各檔案中之說明。
    * 可按下全部執行或使用Ctrl + Enter執行單一區塊之測試(需調整註解內容才可執行單區塊測試)。
  * 於Colab執行:
    * 方法除檔案上傳外，其餘均與本機執行相同，若出現連線中斷之情況，請再次連線(於右上角的reconnect)或調整Change runtime type。 (此調整基本不會用到，除非要使用GPU執行，可能會出現資源耗盡需調整 runtime type)
    * 若出現無法儲存或存在儲存差異的版本時，請點選儲存並選取runtime --> restart session and run all。


__4. 可能遇到的問題:__
  * 本地端:
    * ‼️請勿於執行過程中開啟正在接收輸入之檔案，否則將會造成執行中斷，若要確認取得資料是否正確，可將其複製後再查看。
    * 於近期測試時發現，104網頁對於短時間大量連線，加入了連線次數之限制，於執行過程中可能出現Request failed: 429 Client Error: Too Many Requests for url的問題。(若文字輸出內容已超過可顯示之範圍，可點選View as a scrollable element or open in a text editor 以查看當前執行狀況)
    * 此問題可能解法為:
      * 將資料分端分次執行。(待單位時間限制結束即可再次執行，然而，我並無對此時間具體為何進行測試，僅可確定12小時後定可再次執行)。
      * 更改電腦ip，讓伺服器認定為不同裝置所發出之請求。(此部分需了解公司網路設計，無法確定是否可以更改)。
      * 使用Colab，然而，同樣會遇到此問題，解法於下方進行說明。
  * Google Colab:
    * 使用此方法由於需要較多次的傳輸，因此，速度會較本機稍慢。
    * ‼️請勿於執行過程中開啟正在接收輸入之檔案，否則將會造成執行中斷，若要確認取得資料是否正確，可將其複製後再查看。
    * 由於此方法可視為一種遠端連線，請注意執行完成之時間，勿使其待機時間過久，否則斷連後可能無法取得先前執行所得之結果。
    * 當執行一段時間後仍會有 Request failed: 429 Client Error: Too Many Requests for url的問題，此問題可利用colab執行的特行解決，於此僅大致說明可解決之原因，詳細說明若有興趣請自行搜尋。
      * 解決方法: (由於我所使用的為英文版本，若使用中文版，請自行對照)
        * 儲存當次執行結果後，點選runtime --> disconnect and delete runtime 。
        * 此步驟將會刪除所有已上傳及執行所得之結果，因此，請確保已將先前結果下載。
        * 若有與雲端硬碟進行連接(mount)，則硬碟中內容不會受到影像，僅需於再次執行時更改儲存結果之檔案名稱，以免被取代。
        * 若此方法無用或過於麻煩，可以選擇使用無痕模式開啟同一.ipynb檔案，即可繼續執行，此方法同樣需再次上傳所需輸入之內容。
      * 解法簡要說明:
        * 詳細解釋請參考影像檔與容器使用說明。
        * 重新連接即連接之不同的容器使用，可能持有不同的資訊(port, ip等等)，可被104網頁認定為不同使用者之連線，因此可以再次連接以取得資料。
        * 重新連線後上傳之檔案消失，是因為再次連線後所開啟的使用者介面所連接的並非一開始所使用的容器，且在無與雲端硬碟連接的情況下，所有操作均於暫存空間中進行，無法自動保存，且隨容器關閉一同消失。

  
  __5. 爬蟲程序更動方式簡述說明__ \
⭐此部分內容僅提供大略修改方向，具體更改方式仍須依據欲抓取的網頁結構進行調整。(於進行過程中需開啟開發人員工具(F12 or Ctrl + Shift + i)以對html tag的使用及結構有所了解)
  * 取得欲抓取的網頁連結後，若須帶入關鍵字進行搜尋，可先透過url得到關鍵字帶入的方式。(可知道是否需要對其做url encode的處理)
  * 若下一步得到的頁面為類似表格狀結構，同時須取得多筆資料內容(存有多個搜尋結果)，可透過table的特性，取到連結至每一個子連結頁面所需的部分url內容。(若直接連接至所需頁面可直接跳過這一步)
  * 到達資訊所在之頁面後，可先透過 **soup = BeautifulSoup(res.text, "html.parser")** 的使用，得到當前頁面的回傳內容，並與開發人員工具頁中的內容對比。
  * 若取得內容較開發人員工具中的有缺少，則需找到最外層的<div> tag，並使用 **parent_table = soup.find('div', id="tag id")** 查看是否成功取得該元素。 (若無此問題，可跳過此步驟)
  * 最後，確認所有需要的資訊均被取得後，即可針對各網頁的架構不同，調整資訊取出的方式，主要的方法仍是使用 **item.find('1','2')**，其中item為經過上述方法取得之含所有所需內容的元素(或是暫存的參數)，'1'為存放內容的html tag種類，如: class, div, table, '2'為可為一識別該元素的標籤，通常為'id'，也有部分使用'class_'，表示方法的不同可參考上序檔案(.ipynb files)中的寫法。
  * 取出的內容通常需要經過字串的切分或使用正則表達式以呈現出適當的內容，此部分可自由選用，若無法自行切分，於取得所有所需內容並形成單一字串後，可用chatGPT完成(須注意，若要使用此方法，需保留標籤標題的部分，即可識別之固定內容部分)
  * 於存入.csv檔時，為確保可使用excel開啟，將儲存格式調整為utf-8 with bom, 即利用程式碼 **file.write('\ufeff')** 進行調整，請注意勿刪除。
  * 若最終仍有少數資料無法取得，可於開發者頁面中，右鍵點選該元件，並點選以HTML形式編輯，即可看到完整的元件呈現。
  * 由於各網頁的結構與限制不同，此方法僅提供大略調整方向，細部內容仍需對html 元件使用進行分析以調整。
  * 我將先前編寫時所用道的參考資料與網頁置於此，若有需要可以參考😊
    * https://github.com/kobojp/scraper_104_1111
    * https://github.com/SuYenTing/Python-web-crawler/blob/main/104_job_search.py
    * https://ithelp.ithome.com.tw/articles/10202121






📝 由於個人的時間規劃，最終決定提前結束實習，因時間原因，無法當面告知並完成交接，僅能以此方式進行說明，因為無法確保交接內容已清楚表達，若有任何問題或不清楚地可再與我聯繫，聯絡方式: eliana22680@gmail.com，feel free to contact，但因個人原因無法保證回復時間。

另外，也很感謝妳提供的這項工作，讓我的實習期間也算是收穫不少，謝謝妳當初在電梯間的問候與偶爾的閒聊，讓我意識到大家其實沒有那麼難以接近。
對於各位長姐而言，我只是一個短暫的過客。因此，我希望我的離開也能夠是平淡的，所以我選擇將這段文字留在這裡。若有機會讓你們知道我的感謝，我將不勝榮幸；若沒有，也無需勉強。僅當作是紀錄這段經歷中的所思所感。
唯一的請求是，希望這段內容不被不認識的人得知。再次感謝。
這三個月來，感謝你們的陪伴與指教，從無措的被繼遠哥帶到辦公室，見到了曾經於面試時見過的主管，一句看似玩笑的"有沒有覺得看到了稍微熟悉一點的人?"，開啟了這段旅程，
感謝郁婷學姊在百忙中還要跟我解說公司流程，時常還要回答我許多問題，有些可能甚至算得上愚蠢，謝謝妳的包容與耐心。
謝謝繼遠學長提供的教學影片，還有茶水間內細聲地詢問是否需要與我講解系統存在的原因，及使用角色的不同對資料呈現上的影響，很遺憾最後沒有與您有更多的交流，但仍感謝您的溫暖。
謝謝于宸學長，在得知內線電話無法使用後，雖然很忙，仍撥空協助解決，也謝謝Alley和慕宣學姊，讓我認識了附近許多好吃的小店，也謝謝你們願意和我這個i人有稍多的交流，
還有朝漪姐姐，在我還認不清楚大家誰是誰的時候，在樓梯口認出了我並跟我分享她豐盛的午餐菜色，謝謝溫暖的妳還有明惠姊姊，雖然平時的交流不多，但謝謝妳在先前開會中，自我介紹時給予即時的反應，讓我顯得沒那麼尷尬，
也謝謝Terry哥，在電梯間的句句午餐吃甚麼，還有時而像是不在同一頻道上的閒談，讓我覺得好像在這裡也不需要如此拘謹，
除了這些，還有許多許多的感謝，但我的語言表達無法將他們全部道明，僅能以一句最簡單的感謝做為這段旅程的結束，
感謝這三個月來的陪伴、包容與指教，預祝各位未來一切順遂!


    
